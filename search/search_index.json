{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>A engenharia de software \u00e9 um campo da computa\u00e7\u00e3o que se dedica ao estudo, desenvolvimento e manuten\u00e7\u00e3o de sistemas de software de maneira estruturada e eficiente. Seu objetivo \u00e9 aplicar princ\u00edpios da engenharia para garantir que os sistemas sejam confi\u00e1veis, escal\u00e1veis, seguros e f\u00e1ceis de manter.</p>"},{"location":"#principios-da-engenharia-de-software","title":"Princ\u00edpios da Engenharia de Software","text":"<p>Os princ\u00edpios fundamentais da engenharia de software incluem modularidade, reutiliza\u00e7\u00e3o de c\u00f3digo, manuten\u00e7\u00e3o cont\u00ednua e boas pr\u00e1ticas de desenvolvimento. Esses princ\u00edpios permitem a cria\u00e7\u00e3o de sistemas robustos e adapt\u00e1veis \u00e0s mudan\u00e7as tecnol\u00f3gicas e aos requisitos do usu\u00e1rio.</p>"},{"location":"#ciclo-de-vida-do-software","title":"Ciclo de Vida do Software","text":"<p>O desenvolvimento de software segue um ciclo de vida, que pode incluir as seguintes etapas:</p> <ol> <li>Levantamento de Requisitos - Defini\u00e7\u00e3o clara dos objetivos e funcionalidades do software.</li> <li>Projeto (Design) - Elabora\u00e7\u00e3o da arquitetura do sistema, defini\u00e7\u00e3o de tecnologias e escolha de padr\u00f5es de projeto.</li> <li>Implementa\u00e7\u00e3o - Desenvolvimento do software utilizando linguagens de programa\u00e7\u00e3o adequadas.</li> <li>Testes - Avalia\u00e7\u00e3o do software para garantir sua qualidade e funcionamento correto.</li> <li>Implanta\u00e7\u00e3o - Distribui\u00e7\u00e3o do software para uso real.</li> <li>Manuten\u00e7\u00e3o e Atualiza\u00e7\u00e3o - Corre\u00e7\u00e3o de erros, melhorias e adi\u00e7\u00e3o de novas funcionalidades.</li> </ol>"},{"location":"#metodologias-de-desenvolvimento","title":"Metodologias de Desenvolvimento","text":"<p>Existem diversas metodologias para guiar o processo de desenvolvimento, entre as mais utilizadas est\u00e3o:</p> <ul> <li>Modelo Cascata: Segue uma sequ\u00eancia linear de etapas, ideal para projetos com requisitos bem definidos.</li> <li>Metodologias \u00c1geis: Como Scrum e Kanban, promovem desenvolvimento iterativo, colabora\u00e7\u00e3o entre equipes e entrega cont\u00ednua de software.</li> <li>DevOps: Integra\u00e7\u00e3o entre desenvolvimento e opera\u00e7\u00e3o para automa\u00e7\u00e3o e melhoria cont\u00ednua do software.</li> </ul>"},{"location":"#desafios-na-engenharia-de-software","title":"Desafios na Engenharia de Software","text":"<p>Os engenheiros de software enfrentam desafios como:</p> <ul> <li>Gerenciamento de complexidade em grandes sistemas.</li> <li>Manuten\u00e7\u00e3o e atualiza\u00e7\u00e3o de c\u00f3digo legado.</li> <li>Garantia de seguran\u00e7a contra amea\u00e7as cibern\u00e9ticas.</li> <li>Adapta\u00e7\u00e3o a novas tecnologias e paradigmas de programa\u00e7\u00e3o.</li> </ul> <p>A engenharia de software \u00e9 uma \u00e1rea essencial para a inova\u00e7\u00e3o e evolu\u00e7\u00e3o da tecnologia, permitindo a cria\u00e7\u00e3o de solu\u00e7\u00f5es eficientes e confi\u00e1veis para os desafios do mundo moderno.</p>"},{"location":"data_pipelines/","title":"Pipelines de Dados","text":"<p>Pipelines de dados s\u00e3o a base para o sucesso em an\u00e1lises de dados e aprendizado de m\u00e1quina. Mover dados de diversas fontes variadas e process\u00e1-los para fornecer contexto \u00e9 a diferen\u00e7a entre ter dados e obter valor deles.</p>"},{"location":"data_pipelines/pocket_reference/01-introduction-to-data-pipelines/","title":"Introdu\u00e7\u00e3o a Pipelines de Dados","text":"<p>Por tr\u00e1s de cada dashboard brilhante, modelo de aprendizado de m\u00e1quina e insight que muda neg\u00f3cios, est\u00e1 o dado. N\u00e3o apenas dados brutos, mas dados coletados de in\u00fameras fontes que precisam ser limpos, processados e combinados para entregar valor. A famosa frase \"dados s\u00e3o o novo petr\u00f3leo\" provou ser verdadeira. Assim como o petr\u00f3leo, o valor dos dados est\u00e1 em seu potencial ap\u00f3s serem refinados e entregues ao consumidor. Tamb\u00e9m como o petr\u00f3leo, s\u00e3o necess\u00e1rios pipelines eficientes para entregar dados atrav\u00e9s de cada est\u00e1gio de sua cadeia de valor.</p>"},{"location":"data_pipelines/pocket_reference/01-introduction-to-data-pipelines/#o-que-sao-pipelines-de-dados","title":"O Que S\u00e3o Pipelines de Dados?","text":"<p>Pipelines de dados s\u00e3o conjuntos de processos que movem e transformam dados de v\u00e1rias fontes para um destino onde novo valor pode ser derivado. Eles s\u00e3o a base das capacidades de an\u00e1lise, relat\u00f3rios e aprendizado de m\u00e1quina.</p> <p>A complexidade de um pipeline de dados depende do tamanho, estado e estrutura dos dados de origem, bem como das necessidades do projeto de an\u00e1lise. Na sua forma mais simples, pipelines podem extrair dados de uma \u00fanica fonte, como uma API REST, e carregar para um destino, como uma tabela SQL em um data warehouse. Na pr\u00e1tica, no entanto, pipelines geralmente consistem em m\u00faltiplas etapas, incluindo extra\u00e7\u00e3o de dados, pr\u00e9-processamento de dados, valida\u00e7\u00e3o de dados e entrega dos dados ao seu destino final. Pipelines frequentemente cont\u00eam tarefas de m\u00faltiplos sistemas e linguagens de programa\u00e7\u00e3o. Al\u00e9m disso, equipes de dados geralmente possuem e mant\u00eam v\u00e1rios pipelines de dados que compartilham depend\u00eancias e precisam ser coordenados.</p>"},{"location":"data_pipelines/pocket_reference/01-introduction-to-data-pipelines/#quem-constroi-pipelines-de-dados","title":"Quem Constr\u00f3i Pipelines de Dados?","text":"<p>Com a populariza\u00e7\u00e3o da computa\u00e7\u00e3o em nuvem e do software como servi\u00e7o (SaaS), o n\u00famero de fontes de dados que as organiza\u00e7\u00f5es precisam entender explodiu. Ao mesmo tempo, a demanda por dados para alimentar modelos de aprendizado de m\u00e1quina, pesquisas de ci\u00eancia de dados e insights sens\u00edveis ao tempo \u00e9 maior do que nunca. Para acompanhar, a engenharia de dados emergiu como um papel fundamental nas equipes de an\u00e1lise. Engenheiros de dados se especializam em construir e manter os pipelines de dados que sustentam o ecossistema de an\u00e1lise.</p> <p>O objetivo de um engenheiro de dados n\u00e3o \u00e9 simplesmente carregar dados em um data warehouse. Engenheiros de dados trabalham de perto com cientistas de dados e analistas para entender o que ser\u00e1 feito com os dados e ajudar a trazer suas necessidades para um estado de produ\u00e7\u00e3o escal\u00e1vel.</p> <p>Engenheiros de dados se orgulham de garantir a validade e a pontualidade dos dados que entregam. Isso significa testar, alertar e criar planos de conting\u00eancia para quando algo der errado. E sim, algo eventualmente dar\u00e1 errado!</p> <p>As habilidades espec\u00edficas de um engenheiro de dados dependem um pouco da pilha de tecnologia que sua organiza\u00e7\u00e3o usa. No entanto, h\u00e1 algumas habilidades comuns que todos os bons engenheiros de dados possuem.</p>"},{"location":"data_pipelines/pocket_reference/01-introduction-to-data-pipelines/#fundamentos-de-sql-e-data-warehousing","title":"Fundamentos de SQL e Data Warehousing","text":"<p>Engenheiros de dados precisam saber como consultar bancos de dados, e SQL \u00e9 a linguagem universal para fazer isso. Engenheiros de dados experientes sabem como escrever SQL de alto desempenho e entendem os fundamentos de data warehousing e modelagem de dados. Mesmo que uma equipe de dados inclua especialistas em data warehousing, um engenheiro de dados com fundamentos de warehousing \u00e9 um parceiro melhor e pode preencher lacunas t\u00e9cnicas mais complexas que surgem.</p>"},{"location":"data_pipelines/pocket_reference/01-introduction-to-data-pipelines/#python-eou-java","title":"Python e/ou Java","text":"<p>A linguagem na qual um engenheiro de dados \u00e9 proficiente depender\u00e1 da pilha de tecnologia de sua equipe, mas de qualquer forma, um engenheiro de dados n\u00e3o conseguir\u00e1 fazer o trabalho com ferramentas \"sem c\u00f3digo\", mesmo que tenha algumas boas em seu arsenal. Python e Java atualmente dominam na engenharia de dados, mas novos como Go est\u00e3o surgindo.</p>"},{"location":"data_pipelines/pocket_reference/01-introduction-to-data-pipelines/#computacao-distribuida","title":"Computa\u00e7\u00e3o Distribu\u00edda","text":"<p>Resolver um problema que envolve grande volume de dados e o desejo de processar dados rapidamente levou os engenheiros de dados a trabalhar com plataformas de computa\u00e7\u00e3o distribu\u00edda. A computa\u00e7\u00e3o distribu\u00edda combina o poder de m\u00faltiplos sistemas para armazenar, processar e analisar grandes volumes de dados de forma eficiente.</p> <p>Um exemplo popular de computa\u00e7\u00e3o distribu\u00edda em an\u00e1lises \u00e9 o ecossistema Hadoop, que inclui armazenamento de arquivos distribu\u00eddos via Hadoop Distributed File System (HDFS), processamento via MapReduce, an\u00e1lise de dados via Pig, e mais. O Apache Spark \u00e9 outro framework de processamento distribu\u00eddo popular, que est\u00e1 rapidamente superando o Hadoop em popularidade.</p> <p>Embora nem todos os pipelines de dados exijam o uso de computa\u00e7\u00e3o distribu\u00edda, os engenheiros de dados precisam saber como e quando utilizar tal framework.</p>"},{"location":"data_pipelines/pocket_reference/01-introduction-to-data-pipelines/#administracao-basica-de-sistemas","title":"Administra\u00e7\u00e3o B\u00e1sica de Sistemas","text":"<p>Espera-se que um engenheiro de dados seja proficiente na linha de comando do Linux e seja capaz de realizar tarefas como analisar logs de aplicativos, agendar cron jobs e solucionar problemas de firewall e outras configura\u00e7\u00f5es de seguran\u00e7a. Mesmo trabalhando totalmente em um provedor de nuvem como AWS, Azure ou Google Cloud, eles acabar\u00e3o usando essas habilidades para fazer os servi\u00e7os em nuvem funcionarem juntos e implantar pipelines de dados.</p>"},{"location":"data_pipelines/pocket_reference/01-introduction-to-data-pipelines/#uma-mentalidade-orientada-a-objetivos","title":"Uma Mentalidade Orientada a Objetivos","text":"<p>Um bom engenheiro de dados n\u00e3o possui apenas habilidades t\u00e9cnicas. Eles podem n\u00e3o interagir com os stakeholders regularmente, mas os analistas e cientistas de dados da equipe certamente o far\u00e3o. O  engenheiro de dados tomar\u00e1 melhores decis\u00f5es arquitet\u00f4nicas se estiver ciente do motivo pelo qual  est\u00e1 construindo um pipeline em primeiro lugar.</p>"},{"location":"data_pipelines/pocket_reference/01-introduction-to-data-pipelines/#por-que-construir-pipelines-de-dados","title":"Por Que Construir Pipelines de Dados?","text":"<p>Da mesma forma que a ponta do iceberg \u00e9 tudo o que pode ser visto por um navio que passa, o produto final do fluxo de trabalho de an\u00e1lise \u00e9 tudo o que a maioria de uma organiza\u00e7\u00e3o v\u00ea. Executivos veem dashboards e gr\u00e1ficos impec\u00e1veis. O marketing compartilha insights bem embalados nas redes sociais. O suporte ao cliente otimiza o atendimento do call center com base no resultado de um modelo preditivo de demanda.</p> <p>O que a maioria das pessoas fora da \u00e1rea de an\u00e1lise muitas vezes n\u00e3o consegue apreciar \u00e9 que, para gerar o que \u00e9 visto, h\u00e1 uma maquinaria complexa que \u00e9 invis\u00edvel. Para cada dashboard e insight que um analista de dados gera e para cada modelo preditivo desenvolvido por um cientista de dados, h\u00e1 pipelines de dados trabalhando nos bastidores. N\u00e3o \u00e9 incomum que um \u00fanico dashboard, ou mesmo uma \u00fanica m\u00e9trica, seja derivado de dados originados em m\u00faltiplos sistemas de origem. Al\u00e9m disso, pipelines de dados fazem mais do que apenas extrair dados de fontes e carreg\u00e1-los em tabelas de banco de dados simples ou arquivos planos para os analistas usarem. Os dados brutos s\u00e3o refinados ao longo do caminho para serem limpos, estruturados, normalizados, combinados, agregados e, \u00e0s vezes, anonimizados ou de outra forma protegidos. Em outras palavras, h\u00e1 muito mais acontecendo abaixo da linha d'\u00e1gua.</p>"},{"location":"data_pipelines/pocket_reference/01-introduction-to-data-pipelines/#como-os-pipelines-sao-construidos","title":"Como os Pipelines S\u00e3o Constru\u00eddos?","text":"<p>Junto com os engenheiros de dados, in\u00fameras ferramentas para construir e dar suporte a pipelines de dados surgiram nos \u00faltimos anos. Algumas s\u00e3o open source, outras comerciais, e algumas s\u00e3o desenvolvidas internamente. Alguns pipelines s\u00e3o escritos em Python, outros em Java, alguns em outra linguagem, e alguns sem c\u00f3digo algum.</p> <p>Al\u00e9m disso, pipelines n\u00e3o s\u00e3o apenas constru\u00eddos - eles s\u00e3o monitorados, mantidos e estendidos. Os engenheiros de dados s\u00e3o respons\u00e1veis n\u00e3o apenas por entregar dados uma vez, mas por construir pipelines e infraestrutura de suporte que entreguem e processem dados de forma confi\u00e1vel, segura e pontual. N\u00e3o \u00e9 uma tarefa f\u00e1cil, mas quando \u00e9 bem feita, o valor dos dados de uma organiza\u00e7\u00e3o pode realmente ser desbloqueado.</p>"},{"location":"data_pipelines/pocket_reference/02-a-modern-data-infrastructure/","title":"Uma Infraestrutura de Dados Moderna","text":"<p>Antes de decidir sobre produtos e design para construir pipelines, vale a pena entender o que comp\u00f5e uma pilha de dados moderna. Como na maioria das coisas em tecnologia, n\u00e3o h\u00e1 uma \u00fanica maneira correta de projetar seu ecossistema de an\u00e1lise ou escolher produtos e fornecedores. Independentemente disso, h\u00e1 algumas necessidades e conceitos chave que se tornaram padr\u00e3o na ind\u00fastria e estabelecem o cen\u00e1rio para as melhores pr\u00e1ticas na implementa\u00e7\u00e3o de pipelines.</p>"},{"location":"data_pipelines/pocket_reference/02-a-modern-data-infrastructure/#diversidade-de-fontes-de-dados","title":"Diversidade de Fontes de Dados","text":"<p>A maioria das organiza\u00e7\u00f5es possui dezenas, se n\u00e3o centenas, de fontes de dados que alimentam seus esfor\u00e7os anal\u00edticos. As fontes de dados variam em muitas dimens\u00f5es abordadas nesta se\u00e7\u00e3o.</p> <p>Os principais componentes de uma infraestrutura de dados moderna</p> <ul> <li>Data warehouses na nuvem e data lakes</li> <li>Ferramentas de ingest\u00e3o de dados</li> <li>Diversidade de fontes de dados</li> <li>Plataformas de orquestra\u00e7\u00e3o de workflows</li> <li>Ferramentas e frameworks de modelagem</li> </ul>"},{"location":"data_pipelines/pocket_reference/02-a-modern-data-infrastructure/#propriedade-do-sistema-de-origem","title":"Propriedade do Sistema de Origem","text":"<p>\u00c9 comum para uma equipe de an\u00e1lise ingerir dados de sistemas de origem que s\u00e3o constru\u00eddos e mantidos pela organiza\u00e7\u00e3o, bem como de ferramentas e fornecedores de terceiros. Por exemplo, uma empresa de e-commerce pode armazenar dados de seu carrinho de compras em um banco de dados PostgreSQL (tamb\u00e9m conhecido como Postgres) por tr\u00e1s de seu aplicativo web. Eles tamb\u00e9m podem usar uma ferramenta de an\u00e1lise web de terceiros, como o Google Analytics, para rastrear o uso em seu site. A combina\u00e7\u00e3o dessas duas fontes de dados \u00e9 necess\u00e1ria para obter uma compreens\u00e3o completa do comportamento do cliente at\u00e9 a compra. Assim, um pipeline de dados que termina com uma an\u00e1lise de tal comportamento come\u00e7a com a ingest\u00e3o de dados de ambas as fontes.</p> <p>Entender a propriedade dos sistemas de origem \u00e9 importante por v\u00e1rias raz\u00f5es. Primeiro, para fontes de dados de terceiros, voc\u00ea provavelmente estar\u00e1 limitado quanto aos dados que pode acessar e como pode acess\u00e1-los. A maioria dos fornecedores disponibiliza uma API REST, mas poucos lhe dar\u00e3o acesso direto aos seus dados na forma de um banco de dados SQL. Ainda menos fornecer\u00e3o muita personaliza\u00e7\u00e3o sobre quais dados voc\u00ea pode acessar e em que n\u00edvel de granularidade.</p> <p>Sistemas constru\u00eddos internamente apresentam \u00e0 equipe de an\u00e1lise mais oportunidades de personalizar os dados dispon\u00edveis, bem como o m\u00e9todo de acesso. No entanto, eles tamb\u00e9m apresentam outros desafios. Os sistemas foram constru\u00eddos com considera\u00e7\u00e3o \u00e0 ingest\u00e3o de dados? Muitas vezes a resposta \u00e9 n\u00e3o, o que tem implica\u00e7\u00f5es que variam desde a ingest\u00e3o colocando uma carga n\u00e3o intencional no sistema at\u00e9 a incapacidade de carregar dados incrementalmente. Se voc\u00ea tiver sorte, a equipe de engenharia que possui o sistema de origem ter\u00e1 tempo e disposi\u00e7\u00e3o para trabalhar com voc\u00ea, mas na realidade das restri\u00e7\u00f5es de recursos, voc\u00ea pode descobrir que n\u00e3o \u00e9 muito diferente de trabalhar com um fornecedor externo.</p>"},{"location":"data_pipelines/pocket_reference/02-a-modern-data-infrastructure/#interface-de-ingestao-e-estrutura-de-dados","title":"Interface de Ingest\u00e3o e Estrutura de Dados","text":"<p>Independentemente de quem possui os dados de origem, como voc\u00ea os obt\u00e9m e em que forma \u00e9 a primeira coisa que um engenheiro de dados examinar\u00e1 ao construir uma nova ingest\u00e3o de dados. Primeiro, qual \u00e9 a interface para os dados? Alguns dos mais comuns incluem os seguintes:</p> <ul> <li>Um banco de dados por tr\u00e1s de um aplicativo, como um banco de dados Postgres ou MySQL</li> <li>Uma camada de abstra\u00e7\u00e3o em cima de um sistema, como uma API REST</li> <li>Uma plataforma de processamento de streams, como o Apache Kafka</li> <li>Um sistema de arquivos de rede compartilhado ou bucket de armazenamento em nuvem contendo logs, arquivos CSV (valores separados por v\u00edrgula) e outros arquivos planos (flat files)</li> <li>Um data warehouse ou data lake</li> <li>Dados em HDFS ou banco de dados HBase</li> </ul> <p>Al\u00e9m da interface, a estrutura dos dados variar\u00e1. Aqui est\u00e3o alguns exemplos comuns:</p> <ul> <li>JSON de uma API REST</li> <li>Dados bem estruturados de um banco de dados MySQL</li> <li>JSON dentro de colunas de uma tabela de banco de dados MySQL</li> <li>Dados de log semiestruturados</li> <li>CSV, formato de largura fixa (FWF) e outros formatos de arquivos planos</li> <li>JSON em arquivos planos</li> <li>Sa\u00edda de stream do Kafka</li> </ul> <p>Cada interface e estrutura de dados apresenta seus pr\u00f3prios desafios e oportunidades. Dados bem estruturados s\u00e3o frequentemente mais f\u00e1ceis de trabalhar, mas geralmente s\u00e3o estruturados no interesse de um aplicativo ou site. Al\u00e9m da ingest\u00e3o dos dados, etapas adicionais no pipeline provavelmente ser\u00e3o necess\u00e1rias para limpar e transformar em uma estrutura em que os dados sejam reduzidos.</p> <p>Dados n\u00e3o estruturados s\u00e3o comuns para alguns empreendimentos anal\u00edticos. Por exemplo, modelos de Processamento de Linguagem Natural (Natural Language Processing - NLP) requerem grandes quantidades de dados de texto livre para treinar e validar. Projetos de Vis\u00e3o Computacional (Computer Vision - CV) requerem imagens e conte\u00fado de v\u00eddeo. Mesmo projetos menos assustadores, como a extra\u00e7\u00e3o de dados de p\u00e1ginas da web, t\u00eam necessidade de dados de texto livre da web, al\u00e9m da marca\u00e7\u00e3o HTML semiestruturada de uma p\u00e1gina da web.</p>"},{"location":"data_pipelines/pocket_reference/02-a-modern-data-infrastructure/#volume-de-dados","title":"Volume de Dados","text":"<p>Embora engenheiros de dados e gerentes de contrata\u00e7\u00e3o gostem de se gabar sobre conjuntos de dados em escala de petabytes, a realidade \u00e9 que a maioria das organiza\u00e7\u00f5es valoriza conjuntos de dados pequenos tanto quanto os grandes. Al\u00e9m disso, \u00e9 comum ingerir e modelar pequenos e grandes conjuntos de dados em conjunto. Embora as decis\u00f5es de design em cada etapa de um pipeline devam levar o volume de dados em considera\u00e7\u00e3o, alto volume n\u00e3o significa alto valor.</p> <p>Dito isso, a maioria das organiza\u00e7\u00f5es tem pelo menos um conjunto de dados que \u00e9 crucial tanto para as necessidades anal\u00edticas quanto para o alto volume. O que \u00e9 alto volume? N\u00e3o h\u00e1 uma defini\u00e7\u00e3o f\u00e1cil, mas no que diz respeito a pipelines, \u00e9 melhor pensar em termos de um espectro, em vez de uma defini\u00e7\u00e3o bin\u00e1ria de conjuntos de dados de alto e baixo volume.</p>"},{"location":"data_pipelines/pocket_reference/02-a-modern-data-infrastructure/#limpeza-e-validade-dos-dados","title":"Limpeza e Validade dos Dados","text":"<p>Assim como h\u00e1 grande diversidade nas fontes de dados, a qualidade dos dados de origem varia muito. Como diz o velho ditado, \"lixo entra, lixo sai\". \u00c9 importante entender as limita\u00e7\u00f5es e defici\u00eancias dos dados de origem e abord\u00e1-las nas se\u00e7\u00f5es apropriadas do seu pipeline.</p> <p>Existem muitas caracter\u00edsticas comuns de \"dados bagun\u00e7ados\", incluindo, mas n\u00e3o limitadas a, as seguintes:</p> <ul> <li>Registros duplicados ou amb\u00edguos</li> <li>Registros \u00f3rf\u00e3os</li> <li>Registros incompletos ou ausentes</li> <li>Erros de codifica\u00e7\u00e3o de texto</li> <li>Formatos inconsistentes (por exemplo, n\u00fameros de telefone com ou sem tra\u00e7os)</li> <li>Dados rotulados incorretamente ou sem r\u00f3tulo</li> </ul> <p>Claro, existem in\u00fameras outras, bem como quest\u00f5es de validade dos dados espec\u00edficas ao contexto do sistema de origem.</p>"},{"location":"data_pipelines/pocket_reference/02-a-modern-data-infrastructure/#latencia-e-largura-de-banda-do-sistema-de-origem","title":"Lat\u00eancia e Largura de Banda do Sistema de Origem","text":"<p>A necessidade de extrair frequentemente grandes volumes de dados dos sistemas de origem \u00e9 um caso de uso comum em uma pilha de dados moderna. No entanto, isso apresenta desafios. As etapas de extra\u00e7\u00e3o de dados nos pipelines devem lidar com limites de taxa de API, tempos de conex\u00e3o esgotados, downloads lentos e propriet\u00e1rios de sistemas de origem que ficam insatisfeitos devido \u00e0 carga colocada em seus sistemas.</p>"},{"location":"data_pipelines/pocket_reference/02-a-modern-data-infrastructure/#data-warehouses-na-nuvem-e-data-lakes","title":"Data Warehouses na Nuvem e Data Lakes","text":"<p>Tr\u00eas coisas transformaram o cen\u00e1rio da an\u00e1lise e do armazenamento de dados nos \u00faltimos 10 anos, e todas est\u00e3o relacionadas ao surgimento dos principais provedores de nuvem p\u00fablica (Amazon, Google e Microsoft).</p> <ul> <li>A facilidade de construir e implantar pipelines de dados, data lakes, data warehouses e processamento anal\u00edtico na nuvem. N\u00e3o h\u00e1 mais necessidade de esperar pelos departamentos de TI e pela aprova\u00e7\u00e3o do or\u00e7amento para grandes custos iniciais. Servi\u00e7os gerenciados -- bancos de dados em particular -- se tornaram comuns.</li> <li>A cont\u00ednua queda nos custos de armazenamento na nuvem.</li> <li>O surgimento de bancos de dados colunar altamente escal\u00e1veis, como Amazon Redshift, Snowflake e Google Big Query.</li> </ul> <p>Um data warehouse \u00e9 onde os dados de diferentes sistemas s\u00e3o armazenados e modelados para suportar an\u00e1lises e outras atividades relacionadas a responder perguntas com esses dados. Os dados em um armaz\u00e9m de dados s\u00e3o estruturados e otimizados para consultas de relat\u00f3rios e an\u00e1lises.</p> <p>Um data lake \u00e9 onde os dados s\u00e3o armazenados, mas sem a estrutura ou otimiza\u00e7\u00e3o de consulta de um armaz\u00e9m de dados. Ele provavelmente conter\u00e1 um grande volume de dados, bem como uma variedade de tipos de dados. Por exemplo, um \u00fanico data lake pode conter uma cole\u00e7\u00e3o de postagens de blog armazenadas como arquivos de texto, arquivos planos extra\u00eddos de um banco de dados relacional e objetos JSON contendo eventos gerados por sensores em um sistema industrial, embora n\u00e3o seja otimizado para consultar esses dados com o objetivo de relat\u00f3rios e an\u00e1lises.</p> <p>H\u00e1 um lugar para ambos, data warehouses e data lakes, no mesmo ecossistema de dados, e os pipelines de dados frequentemente movem dados entre ambos.</p>"},{"location":"data_pipelines/pocket_reference/02-a-modern-data-infrastructure/#ferramentas-de-transformacao-e-modelagem-de-dados","title":"Ferramentas de Transforma\u00e7\u00e3o e Modelagem de Dados","text":"<p>Os termos modelagem de dados e transforma\u00e7\u00e3o de dados s\u00e3o frequentemente usados de forma intercambi\u00e1vel.</p> <ul> <li> <p>Transforma\u00e7\u00e3o de Dados: Transformar dados \u00e9 um termo amplo que \u00e9 representado pelo T em um processo ETL ou ELT. Uma transforma\u00e7\u00e3o pode ser algo t\u00e3o simples quanto converter um timestamp armazenado em uma tabela de um fuso hor\u00e1rio para outro. Tamb\u00e9m pode ser uma opera\u00e7\u00e3o mais complexa que cria uma nova m\u00e9trica a partir de m\u00faltiplas colunas de origem que s\u00e3o agregadas e filtradas atrav\u00e9s de alguma l\u00f3gica de neg\u00f3cios.</p> </li> <li> <p>Modelagem de Dados: A modelagem de dados \u00e9 um tipo mais espec\u00edfico de transforma\u00e7\u00e3o de dados. Um modelo de dados estrutura e define dados em um formato que \u00e9 entendido e otimizado para an\u00e1lise de dados. Um modelo de dados \u00e9 geralmente representado como uma ou mais tabelas em um armaz\u00e9m de dados.</p> </li> </ul> <p>Assim como a ingest\u00e3o de dados, existem v\u00e1rias metodologias e ferramentas presentes em uma infraestrutura de dados moderna. Como mencionado anteriormente, algumas ferramentas de ingest\u00e3o de dados fornecem algum n\u00edvel de capacidades de transforma\u00e7\u00e3o de dados, mas estas s\u00e3o frequentemente bastante simples. Por exemplo, para proteger informa\u00e7\u00f5es pessoalmente identific\u00e1veis (PII), pode ser desej\u00e1vel transformar um endere\u00e7o de e-mail em um valor hash que \u00e9 armazenado no destino final. Tal transforma\u00e7\u00e3o \u00e9 geralmente realizada durante o processo de ingest\u00e3o.</p> <p>Para transforma\u00e7\u00f5es de dados mais complexas e modelagem de dados, \u00e9 desej\u00e1vel buscar ferramentas e frameworks especificamente projetados para a tarefa, como o dbt. Al\u00e9m disso, a transforma\u00e7\u00e3o de dados \u00e9 frequentemente espec\u00edfica ao contexto e pode ser escrita em uma linguagem familiar para engenheiros de dados e analistas de dados, como SQL ou Python.</p> <p>Modelos de dados que ser\u00e3o usados para an\u00e1lise e relat\u00f3rios s\u00e3o tipicamente definidos e escritos em SQL ou atrav\u00e9s de interfaces de usu\u00e1rio de apontar e clicar. Assim como as considera\u00e7\u00f5es de construir versus comprar, h\u00e1 considera\u00e7\u00f5es ao escolher construir modelos usando SQL versus uma ferramenta no-code. SQL \u00e9 uma linguagem altamente acess\u00edvel que \u00e9 comum tanto para engenheiros de dados quanto para analistas. Ela capacita os analistas a trabalhar diretamente com os dados e otimizar o design dos modelos para suas necessidades. Tamb\u00e9m \u00e9 usada em quase todas as organiza\u00e7\u00f5es, proporcionando um ponto de entrada familiar para novos contratados em uma equipe. Na maioria dos casos, escolher um framework de transforma\u00e7\u00e3o que suporte a constru\u00e7\u00e3o de modelos de dados em SQL em vez de interfaces de usu\u00e1rio de apontar e clicar \u00e9 desej\u00e1vel. Voc\u00ea ter\u00e1 muito mais personaliza\u00e7\u00e3o e controle sobre seu processo de desenvolvimento de ponta a ponta.</p>"},{"location":"data_pipelines/pocket_reference/02-a-modern-data-infrastructure/#plataformas-de-orquestracao-de-workflows","title":"Plataformas de Orquestra\u00e7\u00e3o de Workflows","text":"<p>\u00c0 medida que a complexidade e o n\u00famero de pipelines de dados em uma organiza\u00e7\u00e3o crescem, \u00e9 importante introduzir uma plataforma de orquestra\u00e7\u00e3o de workflows na sua infraestrutura de dados. Essas plataformas gerenciam o agendamento e o fluxo de tarefas em uma pipeline. Imagine uma pipeline com uma d\u00fazia de tarefas que variam desde ingest\u00f5es de dados escritas em Python at\u00e9 transforma\u00e7\u00f5es de dados escritas em SQL que devem ser executadas em uma sequ\u00eancia espec\u00edfica e gerenciar depend\u00eancias entre cada tarefa. Toda equipe de dados enfrenta esse desafio, mas felizmente existem v\u00e1rias plataformas de orquestra\u00e7\u00e3o de workflows dispon\u00edveis para aliviar o problema.</p> <p>Algumas plataformas, como Apache Airflow, Luigi e AWS Glue, s\u00e3o projetadas para casos de uso mais gerais e, portanto, s\u00e3o usadas para uma ampla variedade de pipelines de dados. Outras, como Kubeflow Pipelines, s\u00e3o projetadas para casos de uso e plataformas mais espec\u00edficos (workflows de aprendizado de m\u00e1quina constru\u00eddos em cont\u00eaineres Docker no caso do Kubeflow Pipelines).</p>"},{"location":"data_pipelines/pocket_reference/02-a-modern-data-infrastructure/#grafos-aciclicos-dirigidos-directed-acyclic-graphs","title":"Grafos Ac\u00edclicos Dirigidos (Directed Acyclic Graphs)","text":"<p>Quase todas as plataformas modernas de orquestra\u00e7\u00e3o representam o fluxo e as depend\u00eancias das tarefas em um pipeline como um grafo. No entanto, os grafos de pipelines t\u00eam algumas restri\u00e7\u00f5es espec\u00edficas.</p> <p>Os grafos de pipelines tamb\u00e9m devem ser ac\u00edclicos, o que significa que uma tarefa n\u00e3o pode apontar de volta para uma tarefa previamente conclu\u00edda. Em outras palavras, n\u00e3o pode haver ciclos. Se pudesse, ent\u00e3o um pipeline poderia rodar indefinidamente!</p> <p>Com essas duas restri\u00e7\u00f5es em mente, os pipelines de orquestra\u00e7\u00e3o produzem grafos chamados grafos ac\u00edclicos dirigidos (DAGs).</p> <p>DAGs s\u00e3o uma representa\u00e7\u00e3o de um conjunto de tarefas e n\u00e3o onde a l\u00f3gica das tarefas \u00e9 definida. Uma plataforma de orquestra\u00e7\u00e3o \u00e9 capaz de executar tarefas de todos os tipos.</p> <p>A plataforma de orquestra\u00e7\u00e3o executa cada tarefa, mas a l\u00f3gica das tarefas existe como c\u00f3digo SQL e Python, que roda em diferentes sistemas na infraestrutura de dados.</p>"},{"location":"data_pipelines/pocket_reference/02-a-modern-data-infrastructure/#personalizando-sua-infraestrutura-de-dados","title":"Personalizando Sua Infraestrutura de Dados","text":"<p>\u00c9 raro encontrar duas organiza\u00e7\u00f5es com exatamente a mesma infraestrutura de dados. A maioria escolhe ferramentas e fornecedores que atendem \u00e0s suas necessidades espec\u00edficas e constr\u00f3i o restante por conta pr\u00f3pria.</p> <p>Como mencionado anteriormente, dependendo da cultura e dos recursos da sua organiza\u00e7\u00e3o, voc\u00ea pode ser incentivado a construir a maior parte da sua infraestrutura de dados por conta pr\u00f3pria ou a depender de fornecedores SaaS. Independentemente de qual caminho voc\u00ea escolha na escala de construir versus comprar, voc\u00ea pode construir a infraestrutura de dados de alta qualidade necess\u00e1ria para criar pipelines de dados de alta qualidade.</p> <p>O que \u00e9 importante \u00e9 entender suas restri\u00e7\u00f5es (dinheiro, recursos de engenharia, seguran\u00e7a e toler\u00e2ncia ao risco legal) e as compensa\u00e7\u00f5es resultantes.</p>"}]}